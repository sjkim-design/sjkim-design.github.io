---
layout: post
title:  "머신러닝 알고리즘-장단점"
date:   2021-03-29T14:25:52-05:00
author: KSJ
categories: Algorithm
tags: lorem
---
1. 선형모델
- SVM과 로지스틱 회귀분석이
선형모델계열이다.

(1) 장점
- 학습속도 및 예측속도 빠름
- 방대 및 희소 데이터에도 잘 작동
- 계수를 통한 수식으로 변수의 영향도를 쉽게 파악할 수 있다.
(2) 단점
- 변수 간의 상관성이 높은 경우, 
계수 값이 불명확한 경우가 생긴다.
- 샘플에 비해 특성이 많을 때 잘 작동한다.

2. 나이브 베이즈 분류
(1) 장점
- 선형분류기보다 훈련/예측속도가 빠르다
- 고차원 데이터에서 잘 작동하며, 비교적 매개변수에 민감하지 않은 편이다.
(2) 단점
일반화 성능이 조금 뒤쳐진다.

3. 결정트리
(1) 개념: 
- 규칙을 순차적으로 적용하면서 독립변수 공간을 분할하는 분류모형
- CART(분류와 예측)을 수행
- 만들어진 모델을 쉽게 시각할 수 있음
(2) 작동원리
- 독립변수를 선택하여 독립변수에 대한 기준값을 정하여 해당 값 보다 큰 데이터그룹과 작은 데이터그룹으로 나눈다.
- 노드에 속한 데이터 클래스의 비율을 구하여 노드의 조건부 확률분포를 구하는데
이 조건부확률분포를 이용하여 클래스를 예측한다.
- 분류규칙은 부모와 자식 노드 간의 엔트로피를 가장 낮게 만드는 독립변수와 기준값을 찾는 방법이다. 이를 정량화한 것이 정보획득량(information gain)이라고 부른다.
- 모든 독립변수와 가능 기준값에 대한 정보획득량을 구하여 정보획득량이 가장 큰 독립변수와 기준값을 선택한다.
- 분할은 자식마디가 부모마디보다 순수도가 증가할 때 분류된다.
- 분류는 카이제곱통계량p value,지니계수, 엔트로피지수가 분류 기준으로 사용된다.
- 분류가 잘못될 경우의 가지를 제거한다.
(3) 종류
1) ID3
2) C.4.5
3) C.5.0
4) CART
5) CHAID

1)~3)은 기계학습 분야에서 개발/엔트로피, 정보획득량 개념 활용
4)~5)는 통계학 기초/카이스퀘어, T,F검정의 통계분석법 활용
(1) 장점
- if then 형식으로 룰을 이해하기 쉽다.
- 연속형, 범주형 변수 모두 활용 가능
- 변수의 중요도를 산출하여 비교 가능
- 비교적 속도가 빠름

(2) 단점
- 여러 변수를 동시에 고려하지 않고
한 변수를 선택하여 분류하기 때문에
단일 변수에서 차이를 구분하지 못할때 분류율이 떨어짐
- greedy algorithm(문제 해결과정에서
순간마다 최적이라고 생각되는 결정 방식을 택하여 최종 해답에 도달하는 문제해결 방식/계산속도가 큰 장점), Hill climbing(최적의 해를 찾아 값이 증가 또는 감소 방향으로 계속 이동하는 알고리즘)을 사용하는데
이 방식은 최적의 해를 보장하지는 않음
- 연속형 변수값 예측시 적당하지 않음
- 트리 모형이 복잡하면 예측력이 저하되고
해석 또한 어려워짐
- 데이터 변형에 민감, 레코드 개수의 차이에 따라 트리가 많이 달라질 수 있다. 비슷한 수준의 정보량을 가지는 두 변수가 있는데, 이 약간의 차이로 다른 변수가 선택될 경우, 트리 구성이 달라질 수 있다.

 의사결정나무관련http://blog.naver.com/trashx/60099037740
https://muzukphysics.tistory.com/138

전체 비교
https://dohk.tistory.com/170?fbclid=IwAR0GK5uZ6iTh0T2k1Mpz0e1MB9FpGo8EnxAYR9mY5vTDhhT010lCvK0Cg_k

https://wikidocs.net/
https://datascienceschool.net/03%20machine%20learning/12.01%20%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4.html
알고리즘 관련해서 강의가 잇는지
edwith
